{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import cv2\n",
    "from tracker import Tracker \n",
    "from utils import select_bounding_box\n",
    "from video_read_thread import FileVideoStream\n",
    "import time\n",
    "import imutils\n",
    "from random import randint\n",
    "from imutils.video import FPS\n",
    "from people_recognize import PersonRecognizer\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\PYT\\Repos_own\\Video Retail Analysis\\model\\keras_layers\\keras_layer_DecodeDetections.py:174: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\PYT\\Repos_own\\Video Retail Analysis\\model\\keras_loss_function\\keras_ssd_loss.py:166: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "detection_model_path = 'haarcascade_files/haarcascade_frontalface_default.xml'\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "person_detector = PersonRecognizer()\n",
    "\n",
    "def get_faces_from_haar(frame):\n",
    "    bboxes=[]\n",
    "    colors=[]\n",
    "    frame=imutils.resize(frame,width=500)\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    colors.append((randint(0, 255), randint(0, 255), randint(0, 255)))\n",
    "    faces=face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(5,5),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    print(len(faces),\" faces found in the frame\")\n",
    "    if len(faces)>0:\n",
    "        for face in faces:\n",
    "            (x,y,w,h) = faces[0]\n",
    "            bboxes.append((x,y,w,h))\n",
    "            frame2=frame.copy()\n",
    "            frame2 = cv2.rectangle(frame2,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            while cv2.waitKey(1) & 0xFF != ord('q'):\n",
    "                cv2.imshow(\"Press q to continue\",frame2)\n",
    "    return bboxes,colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_people_from_frame(frame,recognizer=person_detector):\n",
    "    height,width,channels=frame.shape\n",
    "    boxes = recognizer.detect_people(frame)\n",
    "    bboxes =[]\n",
    "    colors = []\n",
    "    for box in boxes :\n",
    "        bboxes.append((int(box[-4]*width/512),int(box[-3]*height/512),int(box[-2]*width/512),int(box[-1])*height/512))\n",
    "        colors.append((randint(0, 255), randint(0, 255), randint(0, 255)))\n",
    "    return bboxes,colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set video to load\n",
    "videoPath = r\"video/VID20200315124213.mp4\"\n",
    "#videoPath = r\"C:\\Users\\HP\\PYT\\Repos_dowloaded\\people-counting-opencv\\videos/example_01.mp4\"\n",
    "# Create a video capture object to read videos\n",
    "cap=FileVideoStream(videoPath,queueSize=64).start() \n",
    "# Read first frame\n",
    "success, frame = cap.read()\n",
    "# quit if unable to read the video file\n",
    "#time.sleep(1.0)\n",
    "#if not success:\n",
    "#    print('Failed to read video')\n",
    "#    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES_PER_DETECT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_times = []\n",
    "update_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracker Created ...\n",
      "Tracker Created ...\n",
      "Tracker Created ...\n",
      "Tracker Created ...\n",
      "Tracker Created ...\n",
      "Tracker Created ...\n",
      "Tracker Created ...\n",
      "Tracker Created ...\n",
      "Tracker Created ...\n",
      " cap.more() is False at Frame 251\n",
      "[INFO] elasped time: 66.74\n",
      "[INFO] approx. FPS: 3.76\n"
     ]
    }
   ],
   "source": [
    "#print(bboxes)\n",
    "#bboxes,colors=select_bounding_box(frame)\n",
    "#bboxes,colors=get_faces_from_haar(frame)\n",
    "\n",
    "fps = FPS().start()\n",
    "fr = FRAMES_PER_DETECT\n",
    "bboxes,colors = detect_people_from_frame(frame)\n",
    "multiTracker = Tracker(bboxes,frame,trackerType=\"MOSSE\").multiTracker\n",
    "# Process video and track objects\n",
    "#fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "#writer = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30,(720,1280), True)\n",
    "frames = []\n",
    "frame_no = 0\n",
    "#print(\"Writer created :\",writer.isOpened())\n",
    "while cap.more():\n",
    "    success, frame = cap.read()\n",
    "    fr -=1 \n",
    "    if fr == 0 :\n",
    "        fr = FRAMES_PER_DETECT\n",
    "    #if not success:\n",
    "    #    print(\" Stopped at :\")\n",
    "    #    break \n",
    "    frame_no += 1\n",
    "    if fr == FRAMES_PER_DETECT :\n",
    "        start_time = time.time()\n",
    "        bboxes,colors=detect_people_from_frame(frame)\n",
    "        detect_times.append(time.time()-start_time)\n",
    "        multiTracker = Tracker(bboxes,frame,trackerType=\"MOSSE\").multiTracker\n",
    "    # get updated location of objects in subsequent frames\n",
    "    start_time = time.time()\n",
    "    success, boxes = multiTracker.update(frame)\n",
    "    update_times.append(time.time()-start_time)\n",
    "    # draw tracked objects\n",
    "    for i, newbox in enumerate(boxes):\n",
    "        p1 = (int(newbox[0]), int(newbox[1]))\n",
    "        #p2 = (int(newbox[0] + newbox[2]), int(newbox[1] + newbox[3]))\n",
    "        p2 = (int( newbox[2]), int( newbox[3]))\n",
    "        cv2.rectangle(frame, p1, p2, colors[i], 2, 1)\n",
    "    # show frame\n",
    "    cv2.putText(frame,str(cap.qsize()),(30,30),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),2)\n",
    "    cv2.imshow('MultiTracker', frame)\n",
    "    frames.append(frame)\n",
    "        #print(type(frame))\n",
    "    #writer.write(frame)\n",
    "    # quit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  \n",
    "        print(\"Waitkey\")\n",
    "        break\n",
    "    fps.update()\n",
    "    if cap.more() is False :\n",
    "        print(\" cap.more() is False at Frame\",frame_no)\n",
    "cap.stop()\n",
    "cv2.destroyAllWindows()\n",
    "#writer.release()\n",
    "\n",
    "fps.stop()\n",
    "print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11489101330122625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(update_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.306311845779419"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(detect_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_frames = []\n",
    "for frame in frames :\n",
    "    img = Image.fromarray(frame)\n",
    "    img = img.resize((640,480))\n",
    "    resized_frames.append(np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "writer = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 30,(640,480),True)\n",
    "print(writer.isOpened())\n",
    "fr = 0\n",
    "for frame in resized_frames:\n",
    "    fr += 1\n",
    "#    writer.write(np.random.randint(0, 255, (480,640,3)).astype('uint8'))\n",
    "    writer.write(frame.astype('uint8'))\n",
    "    #print(fr,\" \",np.mean(frame))\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.random.randint(0, 255, (480,640,3)).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0, 255, (480,640,3)).astype('uint8').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_video(r\"video/VID20200315124213.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(path):\n",
    "    vs = FileVideoStream(path).start()\n",
    "    time.sleep(2)\n",
    "    frame_no = 0\n",
    "    while vs.more():\n",
    "        #print(frame_no,end=\" \")\n",
    "        #if not vs.stream.isOpened():\n",
    "        #    break\n",
    "        ret,frame = vs.read()\n",
    "        #if not ret :\n",
    "        #    break\n",
    "        frame_no += 1\n",
    "        cv2.imshow(\"Press Q to exit\",frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  \n",
    "            #print(\"Waitkey\")\n",
    "            break\n",
    "    vs.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frame_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
